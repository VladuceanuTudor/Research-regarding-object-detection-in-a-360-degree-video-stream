# ğŸ”¬ Ghid Complet: Cercetare DetecÈ›ie 360Â°

## ğŸ“¦ Setup IniÈ›ial

### 1. Instalare DependenÈ›e

```bash
# CreeazÄƒ environment virtual (recomandat)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# sau
venv\Scripts\activate  # Windows

# InstaleazÄƒ dependenÈ›e
pip install --upgrade pip
pip install ultralytics opencv-python numpy pandas matplotlib seaborn tqdm
```

**DependenÈ›e principale:**
- `ultralytics` - YOLO11 (include PyTorch)
- `opencv-python` - Procesare imagini
- `numpy` - OperaÈ›ii numerice
- `pandas` - AnalizÄƒ date
- `matplotlib` + `seaborn` - VizualizÄƒri
- `tqdm` - Progress bars

### 2. StructurÄƒ Directoare

```bash
mkdir -p data/samples data/360_datasets
mkdir -p models
mkdir -p results
```

### 3. Download Date 360Â°

#### OpÈ›iunea A: Dataset-uri Publice

**SUN360** (recomand pentru Ã®nceput):
```bash
# 1. ViziteazÄƒ: http://people.csail.mit.edu/jxiao/SUN360/
# 2. Download imagini (selecteazÄƒ un subset mic ~100 imagini)
# 3. Extrage Ã®n data/360_datasets/sun360/
```

**360VOT** (pentru video tracking):
```bash
# 1. ViziteazÄƒ: http://www.votchallenge.net/vot2021/dataset.html
# 2. Download 360Â° sequences
# 3. Extrage Ã®n data/360_datasets/360vot/
```

**Pano3D** (driving scenes):
```bash
# ViziteazÄƒ: https://github.com/TRI-ML/packnet-sfm
# Follow instructions pentru download
```

#### OpÈ›iunea B: Date Proprii

DacÄƒ ai video-uri 360Â° proprii:
```bash
# Extract frame-uri din video
ffmpeg -i your_360_video.mp4 -vf fps=1 data/samples/frame_%04d.jpg
```

#### OpÈ›iunea C: Date Sintetice (pentru testare rapidÄƒ)

Scriptul `benchmark.py` genereazÄƒ automat imagini dummy dacÄƒ nu existÄƒ date.

### 4. Download Modele YOLO11

Modelele se descarcÄƒ automat la prima rulare, dar poÈ›i:

```bash
# Download manual (opÈ›ional)
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolo11n.pt -P models/
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolo11s.pt -P models/
wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolo11m.pt -P models/
```

---

## ğŸš€ Quick Start

### Test Rapid cu Imagine SingurÄƒ

```python
python detection_pipeline.py
```

Acest script va:
1. DescÄƒrca YOLO11n automat
2. Crea o imagine test dacÄƒ nu existÄƒ
3. Rula detecÈ›ia cu metoda `vertical_slice`
4. Salva rezultate Ã®n `results/experiment_1/`

### Benchmark Complet

```python
python benchmark.py
```

Aceasta va:
1. Testa toate metodele (vertical_slice + cubemap)
2. Cu YOLO11n (rapid pentru testare)
3. Genera plots comparative
4. Salva rapoarte Ã®n `results/benchmark/`

---

## ğŸ“Š Rulare Experimente Custom

### Experiment 1: ComparaÈ›ie Vertical Slices

```python
from detection_pipeline import Detection360Pipeline, ExperimentConfig

# Test cu 4 slices
config_4 = ExperimentConfig(
    method='vertical_slice',
    model_name='yolo11n.pt',
    input_image='data/samples/test.jpg',
    output_dir='results/slices_4',
    num_slices=4,
    overlap_ratio=0.15
)

pipeline_4 = Detection360Pipeline(config_4)
results_4 = pipeline_4.process_image(config_4.input_image)

# Test cu 8 slices
config_8 = ExperimentConfig(
    method='vertical_slice',
    model_name='yolo11n.pt',
    input_image='data/samples/test.jpg',
    output_dir='results/slices_8',
    num_slices=8,
    overlap_ratio=0.15
)

pipeline_8 = Detection360Pipeline(config_8)
results_8 = pipeline_8.process_image(config_8.input_image)

# ComparÄƒ
print(f"4 slices: {results_4['metrics']['fps']:.2f} FPS")
print(f"8 slices: {results_8['metrics']['fps']:.2f} FPS")
```

### Experiment 2: Cubemap vs Vertical Slice

```python
# Vertical Slice
config_vs = ExperimentConfig(
    method='vertical_slice',
    model_name='yolo11s.pt',
    input_image='data/samples/test.jpg',
    output_dir='results/vs_test',
    num_slices=6
)

# Cubemap
config_cm = ExperimentConfig(
    method='cubemap',
    model_name='yolo11s.pt',
    input_image='data/samples/test.jpg',
    output_dir='results/cm_test',
    face_size=640
)

# RuleazÄƒ ambele
pipeline_vs = Detection360Pipeline(config_vs)
pipeline_cm = Detection360Pipeline(config_cm)

results_vs = pipeline_vs.process_image(config_vs.input_image)
results_cm = pipeline_cm.process_image(config_cm.input_image)

# ComparÄƒ acurateÈ›e (dacÄƒ ai ground truth)
print(f"Vertical Slice: {len(results_vs['detections'])} detecÈ›ii")
print(f"Cubemap: {len(results_cm['detections'])} detecÈ›ii")
```

### Experiment 3: Toate Modelele YOLO

```python
models = ['yolo11n.pt', 'yolo11s.pt', 'yolo11m.pt']

for model in models:
    config = ExperimentConfig(
        method='vertical_slice',
        model_name=model,
        input_image='data/samples/test.jpg',
        output_dir=f'results/model_{model}',
        num_slices=6
    )
    
    pipeline = Detection360Pipeline(config)
    results = pipeline.process_image(config.input_image)
    
    print(f"{model}: {results['metrics']['fps']:.2f} FPS, "
          f"{len(results['detections'])} detecÈ›ii")
```

---

## ğŸ“ˆ AnalizÄƒ Rezultate

### 1. Citire Rezultate Benchmark

```python
import pandas as pd
import json

# CSV
df = pd.read_csv('results/benchmark/results.csv')
print(df.describe())

# JSON
with open('results/benchmark/results.json') as f:
    results = json.load(f)
```

### 2. Filtrare È™i ComparaÈ›ie

```python
# Best FPS per metodÄƒ
best_fps = df.groupby('method')['fps'].max()
print("Best FPS per method:")
print(best_fps)

# Best accuracy (num detections)
best_det = df.groupby('method')['num_detections'].mean()
print("\nAverage detections per method:")
print(best_det)

# Trade-off FPS vs Detections
import matplotlib.pyplot as plt

plt.scatter(df['fps'], df['num_detections'], 
           c=df['method'].astype('category').cat.codes)
plt.xlabel('FPS')
plt.ylabel('Number of Detections')
plt.title('FPS vs Detection Count')
plt.show()
```

### 3. Statistici Detaliate

```python
# Per metodÄƒ È™i model
summary = df.groupby(['method', 'model']).agg({
    'fps': ['mean', 'std'],
    'total_time': ['mean', 'std'],
    'num_detections': ['mean', 'std']
}).round(3)

print(summary)
```

---

## ğŸ¯ Interpretarea Rezultatelor

### Ce sÄƒ CÄƒutÄƒm:

**1. FPS (Frames Per Second)**
- **Ãnalt (>10 FPS)**: Bun pentru real-time pe Jetson
- **Mediu (5-10 FPS)**: Acceptabil pentru multe aplicaÈ›ii
- **ScÄƒzut (<5 FPS)**: Probleme pentru deployment

**2. NumÄƒr DetecÈ›ii**
- ComparaÈ›i cu ground truth dacÄƒ existÄƒ
- Prea puÈ›ine = missed detections
- Prea multe = false positives

**3. Trade-offs**
- **Vertical Slice**: Mai rapid, dar distorsiuni polare
- **Cubemap**: Mai acurat, dar mai lent (6 inferenÈ›e)

### Decizii:

**Pentru Jetson AGX Xavier:**
- DacÄƒ FPS > 15: Excelent pentru real-time
- DacÄƒ FPS 10-15: Bun cu optimizÄƒri DeepStream
- DacÄƒ FPS < 10: ConsiderÄƒ model mai mic (nano) sau mai puÈ›ine tiles

**Recomandare:**
1. Ãncepe cu `vertical_slice` + `yolo11n` + `6 slices`
2. DacÄƒ acurateÈ›ea nu e suficientÄƒ â†’ `yolo11s` sau `cubemap`
3. DacÄƒ FPS-ul e prea mic â†’ reduce num_slices sau foloseÈ™te nano

---

## ğŸ”§ OptimizÄƒri

### Pentru FPS Mai Mare:

**1. Reduce numÄƒrul de tiles:**
```python
config.num_slices = 4  # Ã®n loc de 6-8
```

**2. FoloseÈ™te model mai mic:**
```python
config.model_name = 'yolo11n.pt'  # nano
```

**3. Increase confidence threshold:**
```python
config.confidence_threshold = 0.5  # mai puÈ›ine false positives
```

**4. Batch processing (pentru cubemap):**
```python
# Ãn loc sÄƒ rulezi 6 inferenÈ›e separate,
# stack feÈ›ele cubului È™i ruleazÄƒ batch inference
# (necesitÄƒ modificÄƒri Ã®n cod)
```

### Pentru AcurateÈ›e Mai Mare:

**1. Increase overlap:**
```python
config.overlap_ratio = 0.25  # mai mult overlap Ã®ntre tiles
```

**2. Mai multe tiles:**
```python
config.num_slices = 8  # acoperire mai finÄƒ
```

**3. Model mai mare:**
```python
config.model_name = 'yolo11m.pt'  # medium
```

---

## ğŸ“ Adnotare Date

DacÄƒ ai imagini 360Â° fÄƒrÄƒ adnotÄƒri:

### Folosind CVAT

```bash
# 1. Instalare CVAT (Docker)
git clone https://github.com/opencv/cvat
cd cvat
docker-compose up -d

# 2. Acces: http://localhost:8080
# 3. Upload imagini 360Â°
# 4. CreazÄƒ task cu 360Â° mode
# 5. AdnoteazÄƒ obiecte
# 6. Export YOLO format
```

### Folosind Label Studio

```bash
pip install label-studio
label-studio start

# Acces: http://localhost:8080
# Import imagini È™i adnoteazÄƒ
```

---

## ğŸš€ Next Steps: Port la DeepStream

DupÄƒ ce ai metodÄƒ optimÄƒ:

**1. ExportÄƒ model pentru TensorRT:**
```python
from ultralytics import YOLO

model = YOLO('yolo11n.pt')
model.export(format='engine', imgsz=640)  # TensorRT
```

**2. CreazÄƒ GStreamer pipeline:**
```python
# Pseudocod DeepStream config
[source]
type=uri
uri=file:///path/to/360_video.mp4

[preprocessing]
custom-lib=/path/to/libpreprocess360.so
num-slices=6

[primary-gie]
model-engine-file=yolo11n.engine
batch-size=6  # proceseazÄƒ toate tiles odatÄƒ

[tracker]
# Optional tracking

[sink]
type=rtsp
```

**3. ImplementeazÄƒ custom preprocessing plugin:**
- Ãn C/C++ pentru DeepStream
- FoloseÈ™te CUDA pentru preprocessing rapid
- IntegreazÄƒ logica de vertical_slice sau cubemap

---

## ğŸ“š Resurse Suplimentare

**Papers:**
- "Distortion-Aware CNNs for Spherical Images" (IJCV 2019)
- "360-Indoor: Towards Learning Real-World Objects in 360Â° Indoor Equirectangular Images" (WACV 2020)
- "Kernel Transformer Networks for Compact Spherical Convolution" (CVPR 2019)

**Tools:**
- **py360convert**: Library pentru conversii 360Â°
- **equilib**: PyTorch library pentru equirectangular ops
- **Spherical-Package**: RotaÈ›ii È™i transformÄƒri spherical

---

**Ready to start! ğŸš€**

RuleazÄƒ `python benchmark.py` pentru primele rezultate!
